- title: "MLsploit: A Framework for Interactive Experimentation with Adversarial Machine Learning Research"
  authors: ""
  venue: "Project Showcase at 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2019)"
  venue-shorthand: KDD'19 Project Showcase
  year: 2019

  paper-home: "https://mlsploit.github.io/"
  pdf: "https://www.kdd.org/kdd2019/docs/KDD2019_Showcase_2062.pdf"
  github: "https://github.com/mlsploit"
  youtube: "https://youtu.be/hlzszoQVgD4"

  icon: mlsploit.png
  icon-fit: cover
  brand: MLsploit
  tagline: A Framework for Interactive Experimentation with Adversarial Machine Learning Research
  summary: |
    MLsploit is a machine learning (ML) evaluation and fortification framework designed for education and research of adversarial ML. It is the first cloud-based tool that allows real-time interactive experimentation with state-of-the-art adversarial ML research through a web-based interface. The MLsploit system has a service-oriented architecture (SOA) that includes a web portal for users to interact with, and a RESTful API to further automate experiments. The research functions integrated in MLsploit can be thought of as modular components which can be combined in different arrangements to create the desired experiment pipeline using an intuitive interface. Since MLsploit leverages Docker containerization in the backend, each component can be implemented in any language and on any platform, and MLsploit glues everything together through well-defined APIs. This flexible component design is agnostic to the underlying implementation of the ML functionality, and hence allows quick development for researchers as well.

- title: "SHIELD: Fast, Practical Defense and Vaccination for Deep Learning using JPEG Compression"
  authors: "Nilaksh Das, Madhuri Shanbhogue, Shang-Tse Chen, Fred Hohman, Siwei Li, Li Chen, Michael E. Kounavis, Duen Horng Chau"
  venue: "24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2018)"
  venue-shorthand: KDD'18
  year: 2018

  paper-home: "https://poloclub.github.io/jpeg-defense/"
  award: Audience Appreciation Award, Runner-up
  pdf: "https://arxiv.org/abs/1802.06816"
  github: "https://github.com/nilakshdas/mlsploit-shield"
  youtube: "https://youtu.be/zUB2-i7rSb4"
  slides: "static/pdf/shield.pdf"

  icon: shield.jpg
  icon-fit: cover
  brand: SHIELD
  tagline: Fast, Practical Defense for Deep Learning
  summary: |
    SHIELD addresses the urgent need for practical defense that can be readily deployed to combat attacks in real-time. It places JPEG compression at the core of our proposed SHIELD defense framework, utilizing its capability to effectively "compress away" such pixel manipulation. 
    
    <ul>
    <li>SHIELD "vaccinates" a model by re-training it with compressed images, where different compression levels are applied to generate multiple vaccinated models that are ultimately used together in an ensemble defense.</li>
    
    <li>SHIELD adds an additional layer of protection by employing randomization at test time that compresses different regions of an image using random compression levels, making it harder for an adversary to estimate the transformation performed.</li>

    <li>Extensive large-scale experiments using the ImageNet dataset shows that SHIELD eliminates up to 94% of black-box attacks and 98% of gray-box attacks delivered by the recent, strongest attacks, such as Carlini-Wagner's L2 and DeepFool.</li>
    
    <li>SHIELD's novel fortified multi-pronged approach is fast and works without requiring knowledge about the model.</li>
    </ul>
    
  bibtex: |
    @article{das2018shield,
      title={SHIELD: Fast, Practical Defense and Vaccination for Deep Learning using JPEG Compression},
      author={Das, Nilaksh and Shanbhogue, Madhuri and Chen, Shang-Tse and Hohman, Fred and Li, Siwei and Chen, Li and Kounavis, Michael E and Chau, Duen Horng},
      booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
      year={2018},
      organization={ACM}
    }


- title: "ShapeShifter: Robust Physical Adversarial Attack on Faster R-CNN Object Detector"
  authors: "Shang-Tse Chen, Cory Cornelius, Jason Martin, Duen Horng Chau"
  venue: "Joint European Conference on Machine Learning and Knowledge Discovery in Databases (ECML-PKDD'18)"
  venue-shorthand: ECML-PKDD'18
  year: 2018

  paper-home: "https://github.com/shangtse/robust-physical-attack"
  pdf: https://arxiv.org/abs/1804.05810
  github: "https://github.com/shangtse/robust-physical-attack"
  youtube: "https://youtu.be/pc2ssNY98LA"

  icon: shapeshifter.gif
  icon-fit: cover
  brand: ShapeShifter
  tagline: 1st Targeted Physical Attack on Faster R-CNN Object Detector
  summary: |
    ShapeShifter is the first targeted physical attack on Faster R-CNN object detector. It generates adversarial stop signs that were consistently mis-detected by Faster R-CNN as the target objects in real drive-by tests, posing a potential threat to autonomous vehicles and other safety-critical computer vision systems.

  bibtex: |
    @inproceedings{chen2018shapeshifter,
      title={ShapeShifter: Robust Physical Adversarial Attack on Faster R-CNN Object Detector},
      author={Chen, Shang-Tse and Cornelius, Cory and Martin, Jason and Chau, Duen Horng Polo},
      booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
      pages={52--68},
      year={2018},
      organization={Springer}
    }


- title: "Barnum: Detecting Document Malware via Control Flow Anomalies in Hardware Traces"
  authors: "Carter Yagemann and Salmin Sultana and Li Chen and Wenke Lee"
  venue: "22nd Information Security Conference (ISC 2019)"
  venue-shorthand: ISC'19
  year: 2019

  paper-home: "https://carteryagemann.com/pages/barnum.html"
  github: "https://github.com/carter-yagemann/barnum-mlsploit"

  icon: barnum.jpg
  icon-fit: cover
  brand: Barnum
  tagline: Deep Learning Software Anomaly Detection
  summary: |
    Barnum is an offline control flow attack detection system that applies deep learning on hardware execution traces to model a program's behavior and detect control flow anomalies. Our implementation analyzes document readers to detect exploits and ABI abuse.
    
  bibtex: |
    @article{yagemann2019barnum,
      title={Barnum: Detecting Document Malware via Control Flow Anomalies in Hardware Traces},
      author={Yagemann, Carter and Sultana, Salmin and Chen, Li and Lee, Wenke},
      booktitle={Proceedings of the 22nd Information Security Conference},
      year={2019},
      organization={ISC}
    }


- title: "AVPass: Leaking and Bypassing Anti-virus Detection Model Automatically"
  authors: "Jinho Jung and Chanil Jeon and Insu Yun and Max Wolotsky and Taesoo Kim"
  venue: "BlackHat USA 17"
  venue-shorthand: BlackHat'17
  year: 2017

  paper-home: "https://github.com/sslab-gatech/avpass"  
  github: "https://github.com/sslab-gatech/avpass"
  youtube: "https://www.youtube.com/watch?v=GkMyobbyl88"
  slides: "https://www.blackhat.com/docs/us-17/thursday/us-17-Jung-AVPASS-Leaking-And-Bypassing-Anitvirus-Detection-Model-Automatically.pdf"

  icon: avpass.jpg
  icon-fit: cover
  brand: AVPass
  tagline: Android Malware Detection Bypass
  summary: |
    AVPASS is a tool for leaking the detection model of Android antivirus (AV) programs, and bypassing the AV detection by using the leaked information coupled with APK perturbation techniques.
    
  bibtex: |
    @article{jung2017avpass,
     title={AVPASS: Leaking and Bypassing Antivirus Detection Model Automatically (to appear)},
     author={Jung, Jinho and Jeon, Chanil and Wolotsky, Max and Yun, Insu and Kim, Taesoo},
     journal={Black Hat USA Briefings (Black Hat USA), Las Vegas, NV},
     year={2017}
    }


- title: "ELF File Perturbation"
  authors: "Jinho Jung"
  venue: "ELF"
  venue-shorthand: ELF
  year: 0

  paper-home: "https://github.com/killvxk/elf-mlsploit"
  github: "https://github.com/killvxk/elf-mlsploit"

  icon: elf.jpg
  icon-fit: cover
  brand: ELF Module
  tagline: ELF File Malware Detection and Bypassing
  summary: |
    ELF module is an end-to-end module to train/classify ELF classifier and perturb sample:

    <ul>
    <li>ELF module trains and classifies Linux malware Classifier (using Nearest Neighbor, SVM, Gaussian Process, Neural Network, and Random Forest algorithms).</li>    
    <li>ELF module perturbs target malware through remove-API (direct to indirect call). </li>    
    </ul>
   
     

- title: "MLsploit SGX"
  authors: "Jinho Jung"
  venue: "SGX"
  venue-shorthand: SGX
  year: 0

  paper-home: "https://github.com/jinhojun/sgx-new-ml"
  github: "https://github.com/jinhojun/sgx-new-ml"

  icon: sgx.jpg
  icon-fit: cover
  brand: SGX Module
  tagline: SGX for privacy-preserving and inference-preventing ML and Adv-ML
  summary: |
    SGX module provides an example of privacy-preserving and inference-preventing ML and Adv-ML:

    <ul>
    <li>SGX module loads encrypted trained model and decrypt inside of the SGX. Also, this module accepts encrypted user-input so we can guarantee privacy even user's machine is compromised. </li>    
    <li>SGX module maintains multiple classifiers and randomly selects which classifier should provide result to user. Since the result is non-deterministic, adversary will end-up with contaminated decision boundary while user can get the precision close to average of all classifiers. Since SGX can protect random number K, we can prevent decision boundary inference.</li>    
    <li>We also build a webpage to guide an user who wants to learn Intel SGX technology so this will help the user to build the first SGX-enabled application step by step. In addition to this, we provide extensive resources for further study of Intel SGX. Please check the following link for detail: (Link: <a href="http://www.sgx101.com/">SGX101</a>)</li>
    </ul>
    

